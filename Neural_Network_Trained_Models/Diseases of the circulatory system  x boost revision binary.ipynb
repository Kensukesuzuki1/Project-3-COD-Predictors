{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependent Libraries (Databricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If running this notebook in Databricks, you will need the following libraries. If these libraries are not installed on your Databricks Cluster, you can simply uncomment and run the following cell to install those libraries in the notebook before you import the dependencies.\n",
    "\n",
    "Libraries needed:\n",
    "- koalas\n",
    "- mlflow\n",
    "- tensorflow\n",
    "- imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.library.installPyPI(\"koalas\")\n",
    "# dbutils.library.installPyPI(\"mlflow\")\n",
    "# dbutils.library.installPyPI(\"tensorflow\")\n",
    "# dbutils.library.installPyPI(\"imblearn\")\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import databricks.koalas as ks\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, utils\n",
    "\n",
    "# Create a Keras model that's compatible with scikit-learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import pickle\n",
    "import tempfile\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model, Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the AWS S3 Mount and Read CSV (Databricks only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCESS_KEY = \"ENTER_YOUR_KEY_HERE\" # dbutils.secrets.get(scope = \"aws\", key = \"aws-access-key\")\n",
    "# SECRET_KEY = \"ENTER_YOUR_KEY_HERE\" # dbutils.secrets.get(scope = \"aws\", key = \"aws-secret-key\")\n",
    "# ENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\n",
    "# AWS_BUCKET_NAME = \"ENTER_YOUR_BUCKET_HERE\" #Or the bucket you saved your data to\n",
    "# MOUNT_NAME = \"mnt_s3\"\n",
    "# s3_uri = f\"s3a://{ACCESS_KEY}:{ENCODED_SECRET_KEY}@{AWS_BUCKET_NAME}\"\n",
    "# mount_uri = f\"/mnt/{MOUNT_NAME}\"\n",
    "# display(dbutils.fs.ls(mount_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read CSVs\n",
    "# df = pd.read_csv(\"/dbfs/mnt/%s/Project 3 Stuff/cod_clean.csv.gz\" % MOUNT_NAME, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV (Local Jupyter Notebook only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSVs\n",
    "df = pd.read_csv(\"../data/cod_clean.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Month of Death</th>\n",
       "      <th>Sex/Gender</th>\n",
       "      <th>Age Groups</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hispanic Origin</th>\n",
       "      <th>Cause of Death Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8th grade or less</td>\n",
       "      <td>June</td>\n",
       "      <td>M</td>\n",
       "      <td>85 years and over</td>\n",
       "      <td>Married</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>White</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>Diseases of the circulatory system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9 - 12th grade, no diploma</td>\n",
       "      <td>January</td>\n",
       "      <td>F</td>\n",
       "      <td>45 - 54 years</td>\n",
       "      <td>Married</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>Diseases of the respiratory system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high school graduate or GED completed</td>\n",
       "      <td>January</td>\n",
       "      <td>F</td>\n",
       "      <td>65 - 74 years</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>Neoplasms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high school graduate or GED completed</td>\n",
       "      <td>January</td>\n",
       "      <td>M</td>\n",
       "      <td>55 - 64 years</td>\n",
       "      <td>Married</td>\n",
       "      <td>Monday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>External causes of morbidity and mortality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high school graduate or GED completed</td>\n",
       "      <td>January</td>\n",
       "      <td>M</td>\n",
       "      <td>75 - 84 years</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>Diseases of the circulatory system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Education Level Month of Death Sex/Gender  \\\n",
       "0                      8th grade or less           June          M   \n",
       "1             9 - 12th grade, no diploma        January          F   \n",
       "2  high school graduate or GED completed        January          F   \n",
       "3  high school graduate or GED completed        January          M   \n",
       "4  high school graduate or GED completed        January          M   \n",
       "\n",
       "          Age Groups Marital Status Day of Week   Race       Hispanic Origin  \\\n",
       "0  85 years and over        Married    Saturday  White               Mexican   \n",
       "1      45 - 54 years        Married    Saturday  White  Non - Hispanic white   \n",
       "2      65 - 74 years        Widowed      Sunday  White  Non - Hispanic white   \n",
       "3      55 - 64 years        Married      Monday  White  Non - Hispanic white   \n",
       "4      75 - 84 years        Married      Sunday  White  Non - Hispanic white   \n",
       "\n",
       "                      Cause of Death Category  \n",
       "0          Diseases of the circulatory system  \n",
       "1          Diseases of the respiratory system  \n",
       "2                                   Neoplasms  \n",
       "3  External causes of morbidity and mortality  \n",
       "4          Diseases of the circulatory system  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary column\n",
    "df = df.drop(columns=[\"ICD Code\", \"Year\", \"Cause of Death\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Education Level\"] != \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Age Groups\"] != \"Age not stated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Marital Status\"] != \"Marital Status unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Day of Week\"] != \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df.loc[(df[\"Cause of Death Category\"] == \"Diseases of the circulatory system\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diseases of the circulatory system                                                                     6045221\n",
       "Neoplasms                                                                                              4432371\n",
       "Diseases of the respiratory system                                                                     1827302\n",
       "External causes of morbidity and mortality                                                             1406382\n",
       "Diseases of the nervous system                                                                         1106993\n",
       "Mental, behavioral and neurodevelopmental disorders                                                     899612\n",
       "Endocrine, nutritional and metabolic diseases                                                           798858\n",
       "Diseases of the digestive system                                                                        704731\n",
       "Certain infectious and parasitic diseases                                                               500454\n",
       "Diseases of the genitourinary system                                                                    457961\n",
       "Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified                 169827\n",
       "Diseases of the musculoskeletal system and connective tissue                                            102032\n",
       "Certain conditions originating in the perinatal period                                                   83728\n",
       "Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism      73114\n",
       "Congenital malformations, deformations and chromosomal abnormalities                                     70007\n",
       "Diseases of the skin and subcutaneous tissue                                                             30517\n",
       "Pregnancy, childbirth and the puerperium                                                                  8230\n",
       "Diseases of the ear and mastoid process                                                                    502\n",
       "Diseases of the eye and adnexa                                                                             331\n",
       "Codes for special purposes                                                                                   5\n",
       "Name: Cause of Death Category, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cause of Death Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kensu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df8[\"Cause of Death Category\"] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df.loc[df['Cause of Death Category'].isin(['Diseases of the nervous system','Neoplasms'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, 'Diseases of the respiratory system', 'External causes of morbidity and mortality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kensu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df9[\"Cause of Death Category\"] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No    5539364\n",
       "Name: Cause of Death Category, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9[\"Cause of Death Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.concat([df8, df9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (11584585, 57)\n"
     ]
    }
   ],
   "source": [
    "dataset = df10.values\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,8]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:16] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "XGBClassifier()\n",
      "Accuracy: 59.85%\n"
     ]
    }
   ],
   "source": [
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model1 = XGBClassifier()\n",
    "model1.fit(X_train, y_train)\n",
    "print(model1)\n",
    "# make predictions for test data\n",
    "y_pred = model1.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle model\n",
    "import pickle\n",
    "file_name = \"binary_xgb_reg.pkl\"\n",
    "\n",
    "# save pickle model \n",
    "pickle.dump(model1, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jolib model\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "bst = model1\n",
    "# filename = 'global.model'\n",
    "\n",
    "bst.save_model('binary_global.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to save the model\n",
    "# joblib.dump(bst, open(filename, 'wb'))\n",
    "\n",
    "# # to load the saved model\n",
    "# bst = joblib.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(X_test[0, :])\n",
    "test_df = test_df.T\n",
    "test_df.to_csv(\"binarysample3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = pd.read_csv(\"sample3.csv\")\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model_loaded.predict(user_input.values)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[[1]], predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pickle model \n",
    "xgb_model_loaded = pickle.load(open(file_name, \"rb\"))\n",
    "#Predict values \n",
    "xgb_model_loaded.predict(user_input.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df4.values\n",
    "# split data into X and y\n",
    "X = dataset[:,1:6]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,6]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))\n",
    "# make predictions for test data\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.loc[(df[\"Cause of Death Category\"] == \"Neoplasms\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df.loc[df['Cause of Death Category'].isin(['Diseases of the nervous system','Diseases of the circulatory system', 'Diseases of the respiratory system', 'External causes of morbidity and mortality'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[\"Cause of Death Category\"] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[\"Cause of Death Category\"] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.concat([df5, df6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df7.values\n",
    "# split data into X and y\n",
    "X = dataset[:,1:6]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,6]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df.loc[(df[\"Cause of Death Category\"] == \"Diseases of the nervous system\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df.loc[df['Cause of Death Category'].isin(['Diseases of the circulatory system','Neoplasms', 'Diseases of the respiratory system', 'External causes of morbidity and mortality'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10[\"Cause of Death Category\"] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11[\"Cause of Death Category\"] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.concat([df10, df11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df12.values\n",
    "# split data into X and y\n",
    "X = dataset[:,1:6]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,6]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\"Education Level\", \"Month of Death\", \"Sex/Gender\", \"Age Groups\", \"Marital Status\", \"Race\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df.loc[df['Cause of Death Category'].isin([\"Diseases of the circulatory system\", 'Diseases of the nervous system','Neoplasms', 'Diseases of the respiratory system', 'External causes of morbidity and mortality'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "onehotencoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88[\"Education Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df88[df88[\"Age Groups\"] != \"Age not stated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df88[df88[\"Marital Status\"] != \"Marital Status unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df88.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in column_list:\n",
    "    # Reshape column data; fit to the one-hot-encoder (expands columns)\n",
    "    X = onehotencoder.fit_transform(df88[column].values.reshape(-1,1)).toarray()\n",
    "    \n",
    "    # Send the one-hot-encoded information from that column to a new dataframe\n",
    "    dfOneHot = pd.DataFrame(X, columns = [column+str(int(i)) for i in range(X.shape[1])])\n",
    "    \n",
    "    # Merge the one-hot-encoded dataframe to the master dataframe\n",
    "    df88 = df88.merge(dfOneHot, how=\"right\", right_index=True, left_index=True)\n",
    "    \n",
    "    # Drop the column selected (no longer needed)\n",
    "    selected_features = df88.drop([column], axis=1)\n",
    "\n",
    "selected_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import User Input\n",
    "user_input = pd.read_csv(\"sample2.csv\")\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(user_input)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "Neural_Net_Mortality_Data",
  "notebookId": 3690730584832149
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

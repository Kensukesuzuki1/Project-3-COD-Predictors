{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependent Libraries (Databricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If running this notebook in Databricks, you will need the following libraries. If these libraries are not installed on your Databricks Cluster, you can simply uncomment and run the following cell to install those libraries in the notebook before you import the dependencies.\n",
    "\n",
    "Libraries needed:\n",
    "- koalas\n",
    "- mlflow\n",
    "- tensorflow\n",
    "- imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.library.installPyPI(\"koalas\")\n",
    "# dbutils.library.installPyPI(\"mlflow\")\n",
    "# dbutils.library.installPyPI(\"tensorflow\")\n",
    "# dbutils.library.installPyPI(\"imblearn\")\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import databricks.koalas as ks\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, utils\n",
    "\n",
    "# Create a Keras model that's compatible with scikit-learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import pickle\n",
    "import tempfile\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model, Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the AWS S3 Mount and Read CSV (Databricks only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCESS_KEY = \"ENTER_YOUR_KEY_HERE\" # dbutils.secrets.get(scope = \"aws\", key = \"aws-access-key\")\n",
    "# SECRET_KEY = \"ENTER_YOUR_KEY_HERE\" # dbutils.secrets.get(scope = \"aws\", key = \"aws-secret-key\")\n",
    "# ENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\n",
    "# AWS_BUCKET_NAME = \"ENTER_YOUR_BUCKET_HERE\" #Or the bucket you saved your data to\n",
    "# MOUNT_NAME = \"mnt_s3\"\n",
    "# s3_uri = f\"s3a://{ACCESS_KEY}:{ENCODED_SECRET_KEY}@{AWS_BUCKET_NAME}\"\n",
    "# mount_uri = f\"/mnt/{MOUNT_NAME}\"\n",
    "# display(dbutils.fs.ls(mount_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read CSVs\n",
    "# df = pd.read_csv(\"/dbfs/mnt/%s/Project 3 Stuff/cod_clean.csv.gz\" % MOUNT_NAME, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV (Local Jupyter Notebook only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSVs\n",
    "df = pd.read_csv(\"../data/cod_clean.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Month of Death</th>\n",
       "      <th>Sex/Gender</th>\n",
       "      <th>Age Groups</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hispanic Origin</th>\n",
       "      <th>Cause of Death Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8th grade or less</td>\n",
       "      <td>June</td>\n",
       "      <td>M</td>\n",
       "      <td>85 years and over</td>\n",
       "      <td>Married</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>White</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>Diseases of the circulatory system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9 - 12th grade, no diploma</td>\n",
       "      <td>January</td>\n",
       "      <td>F</td>\n",
       "      <td>45 - 54 years</td>\n",
       "      <td>Married</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>Diseases of the respiratory system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high school graduate or GED completed</td>\n",
       "      <td>January</td>\n",
       "      <td>F</td>\n",
       "      <td>65 - 74 years</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>Neoplasms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high school graduate or GED completed</td>\n",
       "      <td>January</td>\n",
       "      <td>M</td>\n",
       "      <td>55 - 64 years</td>\n",
       "      <td>Married</td>\n",
       "      <td>Monday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>External causes of morbidity and mortality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high school graduate or GED completed</td>\n",
       "      <td>January</td>\n",
       "      <td>M</td>\n",
       "      <td>75 - 84 years</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>White</td>\n",
       "      <td>Non - Hispanic white</td>\n",
       "      <td>Diseases of the circulatory system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Education Level Month of Death Sex/Gender  \\\n",
       "0                      8th grade or less           June          M   \n",
       "1             9 - 12th grade, no diploma        January          F   \n",
       "2  high school graduate or GED completed        January          F   \n",
       "3  high school graduate or GED completed        January          M   \n",
       "4  high school graduate or GED completed        January          M   \n",
       "\n",
       "          Age Groups Marital Status Day of Week   Race       Hispanic Origin  \\\n",
       "0  85 years and over        Married    Saturday  White               Mexican   \n",
       "1      45 - 54 years        Married    Saturday  White  Non - Hispanic white   \n",
       "2      65 - 74 years        Widowed      Sunday  White  Non - Hispanic white   \n",
       "3      55 - 64 years        Married      Monday  White  Non - Hispanic white   \n",
       "4      75 - 84 years        Married      Sunday  White  Non - Hispanic white   \n",
       "\n",
       "                      Cause of Death Category  \n",
       "0          Diseases of the circulatory system  \n",
       "1          Diseases of the respiratory system  \n",
       "2                                   Neoplasms  \n",
       "3  External causes of morbidity and mortality  \n",
       "4          Diseases of the circulatory system  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary column\n",
    "df = df.drop(columns=[\"ICD Code\", \"Year\", \"Cause of Death\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df24 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cause of Death Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.loc[(df[\"Cause of Death Category\"] == \"Diseases of the circulatory system\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diseases of the circulatory system    6276232\n",
       "Name: Cause of Death Category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"Cause of Death Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kensu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3[\"Cause of Death Category\"] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[df['Cause of Death Category'].isin(['Diseases of the nervous system','Neoplasms', 'Diseases of the respiratory system', 'External causes of morbidity and mortality'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kensu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df2[\"Cause of Death Category\"] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Cause of Death Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (15354796, 48)\n",
      "[17:29:39] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "XGBClassifier(objective='multi:softprob')\n",
      "Accuracy: 86.53%\n"
     ]
    }
   ],
   "source": [
    "dataset = df4.values\n",
    "# split data into X and y\n",
    "X = dataset[:,0:6]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,6]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle model\n",
    "import pickle\n",
    "file_name = \"xgb_reg.pkl\"\n",
    "\n",
    "# save pickle model \n",
    "pickle.dump(model, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jolib model\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "bst = model\n",
    "filename = 'global.model'\n",
    "\n",
    "# to save the model\n",
    "joblib.dump(bst, open(filename, 'wb'))\n",
    "\n",
    "# to load the saved model\n",
    "bst = joblib.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json model\n",
    "model.save_model('disease1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f2cde1064816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_file_name.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bst' is not defined"
     ]
    }
   ],
   "source": [
    "bst.save_model('model_file_name.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(X_test[0, :])\n",
    "test_df = test_df.T\n",
    "test_df.to_csv(\"sample3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = pd.read_csv(\"sample3.csv\")\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model_loaded.predict(user_input.values)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[[1]], predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pickle model \n",
    "xgb_model_loaded = pickle.load(open(file_name, \"rb\"))\n",
    "#Predict values \n",
    "xgb_model_loaded.predict(user_input.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df4.values\n",
    "# split data into X and y\n",
    "X = dataset[:,1:6]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,6]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))\n",
    "# make predictions for test data\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.loc[(df[\"Cause of Death Category\"] == \"Neoplasms\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df.loc[df['Cause of Death Category'].isin(['Diseases of the nervous system','Diseases of the circulatory system', 'Diseases of the respiratory system', 'External causes of morbidity and mortality'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[\"Cause of Death Category\"] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[\"Cause of Death Category\"] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.concat([df5, df6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df7.values\n",
    "# split data into X and y\n",
    "X = dataset[:,1:6]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,6]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df.loc[(df[\"Cause of Death Category\"] == \"Diseases of the nervous system\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df.loc[df['Cause of Death Category'].isin(['Diseases of the circulatory system','Neoplasms', 'Diseases of the respiratory system', 'External causes of morbidity and mortality'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10[\"Cause of Death Category\"] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11[\"Cause of Death Category\"] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.concat([df10, df11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df12.values\n",
    "# split data into X and y\n",
    "X = dataset[:,1:6]\n",
    "X = X.astype(str)\n",
    "Y = dataset[:,6]\n",
    "# encode string input values as integers\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    if encoded_x is None:\n",
    "        encoded_x = feature\n",
    "    else:\n",
    "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\"Education Level\", \"Month of Death\", \"Sex/Gender\", \"Age Groups\", \"Marital Status\", \"Race\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df.loc[df['Cause of Death Category'].isin([\"Diseases of the circulatory system\", 'Diseases of the nervous system','Neoplasms', 'Diseases of the respiratory system', 'External causes of morbidity and mortality'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "onehotencoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88[\"Education Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df88[df88[\"Age Groups\"] != \"Age not stated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df88[df88[\"Marital Status\"] != \"Marital Status unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df88.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in column_list:\n",
    "    # Reshape column data; fit to the one-hot-encoder (expands columns)\n",
    "    X = onehotencoder.fit_transform(df88[column].values.reshape(-1,1)).toarray()\n",
    "    \n",
    "    # Send the one-hot-encoded information from that column to a new dataframe\n",
    "    dfOneHot = pd.DataFrame(X, columns = [column+str(int(i)) for i in range(X.shape[1])])\n",
    "    \n",
    "    # Merge the one-hot-encoded dataframe to the master dataframe\n",
    "    df88 = df88.merge(dfOneHot, how=\"right\", right_index=True, left_index=True)\n",
    "    \n",
    "    # Drop the column selected (no longer needed)\n",
    "    selected_features = df88.drop([column], axis=1)\n",
    "\n",
    "selected_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import User Input\n",
    "user_input = pd.read_csv(\"sample2.csv\")\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(user_input)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "Neural_Net_Mortality_Data",
  "notebookId": 3690730584832149
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
